{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Class 22: More Regression, More Evaluation and LASSO\n",
    "\n",
    "1. log prismia chat\n",
    "1. say hello in the zoom chat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn import datasets, linear_model\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Load the diabetes dataset\n",
    "diabetes_X, diabetes_y = datasets.load_diabetes(return_X_y=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Questions after class Monday\n",
    "\n",
    "Some good questions were asked on the form Monday. Check the [notes](2020-10-26) for insight on the `r2_score` and `mean_square_error`.\n",
    "\n",
    "## Review of Test Train splits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train,X_test, y_train,y_test = train_test_split(diabetes_X, diabetes_y ,\n",
    "                                                  test_size=20,random_state=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## What metric does the `score` method of  `LinearRegression` use?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LinearRegression()"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "regr = linear_model.LinearRegression()\n",
    "regr.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5195208400616668"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "regr.score(X_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5195208400616668"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred = regr.predict(X_test)\n",
    "r2_score(y_test,y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2850.3176917525775"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_squared_error(y_test,y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Digging in deeper to the Linear Regression model\n",
    "\n",
    "Linear regression fitting involvles learning the coefficients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ -32.3074285 , -257.44432972,  513.31945939,  338.46656647,\n",
       "       -766.86983748,  455.85416891,   92.55795582,  184.75163454,\n",
       "        734.92318647,   82.7231425 ])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "regr.coef_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "and an intercept"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "152.39189054201842"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    " regr.intercept_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The linear regression model is\n",
    "\n",
    "$$ y = wx + b$$\n",
    "\n",
    "wehere it stores $w$ in the `coef_` attribute and `b` as the `intercept_`\n",
    "\n",
    "We can check how this works by multiplying one sample by the coefficients, to get a vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ -0.64334474, -13.0473092 ,  53.80033982,  23.71721361,\n",
       "        27.58260658, -12.16168908,  -2.31326921,  -0.47892464,\n",
       "         2.72784249,   3.33733048])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test[0]*regr.coef_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "then taking the sum and adding the intercept"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "234.9126866563482"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sum(X_test[0]*regr.coef_) + regr.intercept_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "and then comparing to the predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "234.91268665634823"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These are not exactly the same due to float rounding erros, but they're very close.\n",
    "\n",
    "````{margin}\n",
    "```{tip}\n",
    "by default `np.sum` sums across both axes so it gets a single value.  we want to only sum on 1 so that we get t\n",
    "````\n",
    "We can also check for the whole test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-2.84217094e-14,  0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "        0.00000000e+00,  0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "        0.00000000e+00,  0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "        1.42108547e-14,  0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "        0.00000000e+00, -1.42108547e-14, -2.84217094e-14,  0.00000000e+00])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "errors = np.sum(X_test*regr.coef_,axis=1) + regr.intercept_ -y_pred\n",
    "errors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "and confirm these are very small"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.4210854715202004e-14"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.max(errors)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It's doing linear regression as we expected.\n",
    "\n",
    "\n",
    "## Changing the complexity in Linear regression\n",
    "\n",
    "It can be important to also know what the model is really doing and see how different features are used or not.  Maybe, for example all of the features are expensive to measure, but for testing we measured a lot of them.  We might want to simultaneously learn which features we actually need *and* the linear model.  \n",
    "\n",
    "LASSO can do that for us it's objective is like linear regression, but it adds an extra term.  This term forces some of the learned coefficients to be 0.  Mulitplying by 0 gives 0, so that's like throwing away that feature. The term is called the $1-norm$, the details of the math are not important here, just the idea that it can reduce the number of features used as well.\n",
    "\n",
    "$$ ||y-wx||_2^2 + \\alpha ||w||_1 $$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.4224899448032938"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lasso = linear_model.Lasso()\n",
    "lasso.fit(X_train, y_train)\n",
    "lasso.score(X_test,y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It uses many fewer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([  0.        ,  -0.        , 358.27498703,   9.7141813 ,\n",
       "         0.        ,   0.        ,  -0.        ,   0.        ,\n",
       "       309.50796119,   0.        ])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lasso.coef_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It has a parameter alpha that must be >0 that we can use to control how many features it uses. When `alpha = 0 ` it's the same as linear regression, but the regular linear regression estimator uses a more numerically stable algorithm for the `fit` method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5272242529276977"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lasso2 = linear_model.Lasso(alpha=.5)\n",
    "lasso2.fit(X_train, y_train)\n",
    "lasso2.score(X_test,y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see tha fewer are 0 now."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([  0.        ,  -0.        , 466.09039819, 140.20195776,\n",
       "        -0.        ,  -0.        , -61.96474668,   0.        ,\n",
       "       405.95829094,   0.        ])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lasso2.coef_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5170933599105026"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "regr.score(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.4516267981295532"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lasso2.score(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.3712605 , 0.45675648, 0.45066569, 0.42134051, 0.47736463])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lasso_cv = cross_val_score(lasso2, diabetes_X, diabetes_y)\n",
    "lasso_cv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.42955643, 0.52259828, 0.4826784 , 0.42650827, 0.55024923])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "regr_cv = cross_val_score(regr,diabetes_X, diabetes_y )\n",
    "regr_cv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.43547756049731523, 0.48231812211149394)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(lasso_cv), np.mean(regr_cv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.55614411, 0.23056092, 0.35357777, 0.62190498, 0.26587602,\n",
       "       0.61819338, 0.41815916, 0.43515232, 0.43436983, 0.68568514])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cross_val_score(regr,diabetes_X, diabetes_y ,cv=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can do cross validation for all three of these models and look at both the mean and the standard deviation.  The mean tells us how well on average each model does on different subsets of the data.\n",
    "The standard deviation is a measure of _spread_ of the scores.  For intuition, another measure of spread is `max(cv_scores) - min(cv_scores)`.\n",
    "\n",
    "````{margin}\n",
    "```{tip}\n",
    "To keep things concise, we can put two values on one line. This creates a `tuple` and prints out both values since it's on the last line of the cell.\n",
    "```\n",
    "````"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.461962361958337, 0.14698789185375888)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "regr_cv = cross_val_score(regr,diabetes_X, diabetes_y ,cv=10)\n",
    "np.mean(regr_cv), np.std(regr_cv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.3211351084864853, 0.09122225780232662)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lasso_cv = cross_val_score(lasso,diabetes_X, diabetes_y ,cv=10)\n",
    "np.mean(lasso_cv), np.std(lasso_cv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.41808972445133297, 0.11927596370400496)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lasso2_cv = cross_val_score(lasso2,diabetes_X, diabetes_y ,cv=10)\n",
    "np.mean(lasso2_cv), np.std(lasso2_cv)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Questions after class\n",
    "\n",
    "### What does the `cv` parameter in `cross_val_score` do?\n",
    "\n",
    "First, let's look at the help."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on function cross_val_score in module sklearn.model_selection._validation:\n",
      "\n",
      "cross_val_score(estimator, X, y=None, *, groups=None, scoring=None, cv=None, n_jobs=None, verbose=0, fit_params=None, pre_dispatch='2*n_jobs', error_score=nan)\n",
      "    Evaluate a score by cross-validation\n",
      "    \n",
      "    Read more in the :ref:`User Guide <cross_validation>`.\n",
      "    \n",
      "    Parameters\n",
      "    ----------\n",
      "    estimator : estimator object implementing 'fit'\n",
      "        The object to use to fit the data.\n",
      "    \n",
      "    X : array-like of shape (n_samples, n_features)\n",
      "        The data to fit. Can be for example a list, or an array.\n",
      "    \n",
      "    y : array-like of shape (n_samples,) or (n_samples, n_outputs),             default=None\n",
      "        The target variable to try to predict in the case of\n",
      "        supervised learning.\n",
      "    \n",
      "    groups : array-like of shape (n_samples,), default=None\n",
      "        Group labels for the samples used while splitting the dataset into\n",
      "        train/test set. Only used in conjunction with a \"Group\" :term:`cv`\n",
      "        instance (e.g., :class:`GroupKFold`).\n",
      "    \n",
      "    scoring : str or callable, default=None\n",
      "        A str (see model evaluation documentation) or\n",
      "        a scorer callable object / function with signature\n",
      "        ``scorer(estimator, X, y)`` which should return only\n",
      "        a single value.\n",
      "    \n",
      "        Similar to :func:`cross_validate`\n",
      "        but only a single metric is permitted.\n",
      "    \n",
      "        If None, the estimator's default scorer (if available) is used.\n",
      "    \n",
      "    cv : int, cross-validation generator or an iterable, default=None\n",
      "        Determines the cross-validation splitting strategy.\n",
      "        Possible inputs for cv are:\n",
      "    \n",
      "        - None, to use the default 5-fold cross validation,\n",
      "        - int, to specify the number of folds in a `(Stratified)KFold`,\n",
      "        - :term:`CV splitter`,\n",
      "        - An iterable yielding (train, test) splits as arrays of indices.\n",
      "    \n",
      "        For int/None inputs, if the estimator is a classifier and ``y`` is\n",
      "        either binary or multiclass, :class:`StratifiedKFold` is used. In all\n",
      "        other cases, :class:`KFold` is used.\n",
      "    \n",
      "        Refer :ref:`User Guide <cross_validation>` for the various\n",
      "        cross-validation strategies that can be used here.\n",
      "    \n",
      "        .. versionchanged:: 0.22\n",
      "            ``cv`` default value if None changed from 3-fold to 5-fold.\n",
      "    \n",
      "    n_jobs : int, default=None\n",
      "        The number of CPUs to use to do the computation.\n",
      "        ``None`` means 1 unless in a :obj:`joblib.parallel_backend` context.\n",
      "        ``-1`` means using all processors. See :term:`Glossary <n_jobs>`\n",
      "        for more details.\n",
      "    \n",
      "    verbose : int, default=0\n",
      "        The verbosity level.\n",
      "    \n",
      "    fit_params : dict, default=None\n",
      "        Parameters to pass to the fit method of the estimator.\n",
      "    \n",
      "    pre_dispatch : int or str, default='2*n_jobs'\n",
      "        Controls the number of jobs that get dispatched during parallel\n",
      "        execution. Reducing this number can be useful to avoid an\n",
      "        explosion of memory consumption when more jobs get dispatched\n",
      "        than CPUs can process. This parameter can be:\n",
      "    \n",
      "            - None, in which case all the jobs are immediately\n",
      "              created and spawned. Use this for lightweight and\n",
      "              fast-running jobs, to avoid delays due to on-demand\n",
      "              spawning of the jobs\n",
      "    \n",
      "            - An int, giving the exact number of total jobs that are\n",
      "              spawned\n",
      "    \n",
      "            - A str, giving an expression as a function of n_jobs,\n",
      "              as in '2*n_jobs'\n",
      "    \n",
      "    error_score : 'raise' or numeric, default=np.nan\n",
      "        Value to assign to the score if an error occurs in estimator fitting.\n",
      "        If set to 'raise', the error is raised.\n",
      "        If a numeric value is given, FitFailedWarning is raised. This parameter\n",
      "        does not affect the refit step, which will always raise the error.\n",
      "    \n",
      "        .. versionadded:: 0.20\n",
      "    \n",
      "    Returns\n",
      "    -------\n",
      "    scores : array of float, shape=(len(list(cv)),)\n",
      "        Array of scores of the estimator for each run of the cross validation.\n",
      "    \n",
      "    Examples\n",
      "    --------\n",
      "    >>> from sklearn import datasets, linear_model\n",
      "    >>> from sklearn.model_selection import cross_val_score\n",
      "    >>> diabetes = datasets.load_diabetes()\n",
      "    >>> X = diabetes.data[:150]\n",
      "    >>> y = diabetes.target[:150]\n",
      "    >>> lasso = linear_model.Lasso()\n",
      "    >>> print(cross_val_score(lasso, X, y, cv=3))\n",
      "    [0.33150734 0.08022311 0.03531764]\n",
      "    \n",
      "    See Also\n",
      "    ---------\n",
      "    :func:`sklearn.model_selection.cross_validate`:\n",
      "        To run cross-validation on multiple metrics and also to return\n",
      "        train scores, fit times and score times.\n",
      "    \n",
      "    :func:`sklearn.model_selection.cross_val_predict`:\n",
      "        Get predictions from each split of cross-validation for diagnostic\n",
      "        purposes.\n",
      "    \n",
      "    :func:`sklearn.metrics.make_scorer`:\n",
      "        Make a scorer from a performance metric or loss function.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(cross_val_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It does different things, depending on what type of value we pass it.  We passed it an `int` (`10`), so what it did was split the data into 10 groups and then trains on 9/10 of those parts and tests on the last one. Then it iterates over those folds.\n",
    "\n",
    "For classification, it can take into consideration the target value (classes) and an additionally specified group in the data.  A good visualization of what it does is shown in the [sklearn docs](https://scikit-learn.org/stable/auto_examples/model_selection/plot_cv_indices.html).\n",
    "\n",
    "It uses StratifiedKfold for classification, but since we're using regression it will use `KFold`. `test_train_split` uses `ShuffleSplit` by default, let's load that too to see what it does.\n",
    "\n",
    "```{warning}\n",
    "The key in the following is to get the _concepts_ not all of the details in how I evaluate and visualize.  I could have made figures separately to explain the concept, but I like to show that Python is self contained.\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import KFold, ShuffleSplit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "kf = KFold(n_splits = 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When we use the `split` method it gives us a generator."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<generator object _BaseKFold.split at 0x7fe19ad6b450>"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kf.split(diabetes_X, diabetes_y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can use this in a loop to get the list of indices that will be used to get the test and train data for each fold.  To visualize what this is  doing, see below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "N_samples = len(diabetes_y)\n",
    "kf_tt_df = pd.DataFrame(index=list(range(N_samples)))\n",
    "i = 1\n",
    "for train_idx, test_idx in kf.split(diabetes_X, diabetes_y):\n",
    "    kf_tt_df['split ' + str(i)] = ['unused']*N_samples\n",
    "    kf_tt_df['split ' + str(i)][train_idx] = 'Train'\n",
    "    kf_tt_df['split ' + str(i)][test_idx] = 'Test'\n",
    "    i +=1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```{margin}\n",
    "How would you use those indices to get a out actual test and train data?\n",
    "```\n",
    "\n",
    "We can count how many times 'Test' and 'Train' appear"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "count_test = lambda part: len([v for v in part if v=='Test'])\n",
    "count_train = lambda part: len([v for v in part if v=='Train'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When we apply this along `axis=1` we to check that each sample is used in exactly 1 test set how may times each sample is used"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "442"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(kf_tt_df.apply(count_test,axis = 1) ==1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "and exactly 9 training sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(kf_tt_df.apply(count_test,axis = 1) ==9)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "the describe helps ensure that all fo the values are exa\n",
    "\n",
    "We can also visualize:\n",
    "````{margin}\n",
    "```{tip}\n",
    "`sns.heatmap` doesn't work on strings, so we can replace them for the plotting\n",
    "```\n",
    "````"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'sns' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-35-040b85a3367f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mcmap\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolor_palette\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"tab10\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m g = sns.heatmap(kf_tt_df.replace({'Test':1,'Train':0}),cmap=cmap[7:9],cbar_kws={'ticks':[.25,.75]},linewidths=0,\n\u001b[1;32m      3\u001b[0m     linecolor='gray')\n\u001b[1;32m      4\u001b[0m \u001b[0mcolorbar\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcollections\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolorbar\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mcolorbar\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_ticklabels\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Train'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'Test'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'sns' is not defined"
     ]
    }
   ],
   "source": [
    "cmap = sns.color_palette(\"tab10\",10)\n",
    "g = sns.heatmap(kf_tt_df.replace({'Test':1,'Train':0}),cmap=cmap[7:9],cbar_kws={'ticks':[.25,.75]},linewidths=0,\n",
    "    linecolor='gray')\n",
    "colorbar = g.collections[0].colorbar\n",
    "colorbar.set_ticklabels(['Train','Test'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that unlike [`test_train_split`](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.train_test_split.html) this does not always randomize and shuffle the data before splitting.\n",
    "\n",
    " If we apply those `lambda` functions along `axis=0`, we can see the size of each test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "split 1     45\n",
       "split 2     45\n",
       "split 3     44\n",
       "split 4     44\n",
       "split 5     44\n",
       "split 6     44\n",
       "split 7     44\n",
       "split 8     44\n",
       "split 9     44\n",
       "split 10    44\n",
       "dtype: int64"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kf_tt_df.apply(count_test,axis = 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "and training set:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "split 1     397\n",
       "split 2     397\n",
       "split 3     398\n",
       "split 4     398\n",
       "split 5     398\n",
       "split 6     398\n",
       "split 7     398\n",
       "split 8     398\n",
       "split 9     398\n",
       "split 10    398\n",
       "dtype: int64"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kf_tt_df.apply(count_train,axis = 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can verify that these splits are the same size as what `test_train_split` does using the right settings.  10-fold splits the data into 10 parts and tests on 1, so that makes a test size of 1/10=.1, so we can use the `train_test_split` and check the length.\n",
    "\n",
    "```\n",
    "X_train2,X_test2, y_train2,y_test2 = train_test_split(diabetes_X, diabetes_y ,\n",
    "                                                  test_size=.1,random_state=0)\n",
    "\n",
    "[len(split) for split in [X_train2,X_test2,]]\n",
    "```\n",
    "\n",
    "Under the hood `train_test_split` uses `ShuffleSplit`\n",
    "We can do a similar experiment as above to see what `ShuffleSplit` does."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>split 1</th>\n",
       "      <th>split 2</th>\n",
       "      <th>split 3</th>\n",
       "      <th>split 4</th>\n",
       "      <th>split 5</th>\n",
       "      <th>split 6</th>\n",
       "      <th>split 7</th>\n",
       "      <th>split 8</th>\n",
       "      <th>split 9</th>\n",
       "      <th>split 10</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Train</td>\n",
       "      <td>Train</td>\n",
       "      <td>Train</td>\n",
       "      <td>Train</td>\n",
       "      <td>Train</td>\n",
       "      <td>Test</td>\n",
       "      <td>Test</td>\n",
       "      <td>Train</td>\n",
       "      <td>Train</td>\n",
       "      <td>Test</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Train</td>\n",
       "      <td>Train</td>\n",
       "      <td>Train</td>\n",
       "      <td>Train</td>\n",
       "      <td>Train</td>\n",
       "      <td>Train</td>\n",
       "      <td>Train</td>\n",
       "      <td>Train</td>\n",
       "      <td>Train</td>\n",
       "      <td>Train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Train</td>\n",
       "      <td>Test</td>\n",
       "      <td>Train</td>\n",
       "      <td>Train</td>\n",
       "      <td>Train</td>\n",
       "      <td>Train</td>\n",
       "      <td>Train</td>\n",
       "      <td>Train</td>\n",
       "      <td>Train</td>\n",
       "      <td>Train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Train</td>\n",
       "      <td>Train</td>\n",
       "      <td>Train</td>\n",
       "      <td>Train</td>\n",
       "      <td>Train</td>\n",
       "      <td>Train</td>\n",
       "      <td>Train</td>\n",
       "      <td>Train</td>\n",
       "      <td>Train</td>\n",
       "      <td>Train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Train</td>\n",
       "      <td>Train</td>\n",
       "      <td>Train</td>\n",
       "      <td>Train</td>\n",
       "      <td>Train</td>\n",
       "      <td>Train</td>\n",
       "      <td>Train</td>\n",
       "      <td>Train</td>\n",
       "      <td>Train</td>\n",
       "      <td>Train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>437</th>\n",
       "      <td>Train</td>\n",
       "      <td>Test</td>\n",
       "      <td>Train</td>\n",
       "      <td>Train</td>\n",
       "      <td>Train</td>\n",
       "      <td>Train</td>\n",
       "      <td>Train</td>\n",
       "      <td>Test</td>\n",
       "      <td>Train</td>\n",
       "      <td>Train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>438</th>\n",
       "      <td>Train</td>\n",
       "      <td>Train</td>\n",
       "      <td>Train</td>\n",
       "      <td>Train</td>\n",
       "      <td>Test</td>\n",
       "      <td>Train</td>\n",
       "      <td>Train</td>\n",
       "      <td>Train</td>\n",
       "      <td>Train</td>\n",
       "      <td>Train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>439</th>\n",
       "      <td>Train</td>\n",
       "      <td>Train</td>\n",
       "      <td>Train</td>\n",
       "      <td>Train</td>\n",
       "      <td>Train</td>\n",
       "      <td>Train</td>\n",
       "      <td>Train</td>\n",
       "      <td>Train</td>\n",
       "      <td>Train</td>\n",
       "      <td>Train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>440</th>\n",
       "      <td>Train</td>\n",
       "      <td>Train</td>\n",
       "      <td>Train</td>\n",
       "      <td>Train</td>\n",
       "      <td>Train</td>\n",
       "      <td>Train</td>\n",
       "      <td>Train</td>\n",
       "      <td>Train</td>\n",
       "      <td>Train</td>\n",
       "      <td>Train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>441</th>\n",
       "      <td>Train</td>\n",
       "      <td>Train</td>\n",
       "      <td>Train</td>\n",
       "      <td>Train</td>\n",
       "      <td>Train</td>\n",
       "      <td>Train</td>\n",
       "      <td>Train</td>\n",
       "      <td>Train</td>\n",
       "      <td>Train</td>\n",
       "      <td>Train</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>442 rows Ã— 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    split 1 split 2 split 3 split 4 split 5 split 6 split 7 split 8 split 9  \\\n",
       "0     Train   Train   Train   Train   Train    Test    Test   Train   Train   \n",
       "1     Train   Train   Train   Train   Train   Train   Train   Train   Train   \n",
       "2     Train    Test   Train   Train   Train   Train   Train   Train   Train   \n",
       "3     Train   Train   Train   Train   Train   Train   Train   Train   Train   \n",
       "4     Train   Train   Train   Train   Train   Train   Train   Train   Train   \n",
       "..      ...     ...     ...     ...     ...     ...     ...     ...     ...   \n",
       "437   Train    Test   Train   Train   Train   Train   Train    Test   Train   \n",
       "438   Train   Train   Train   Train    Test   Train   Train   Train   Train   \n",
       "439   Train   Train   Train   Train   Train   Train   Train   Train   Train   \n",
       "440   Train   Train   Train   Train   Train   Train   Train   Train   Train   \n",
       "441   Train   Train   Train   Train   Train   Train   Train   Train   Train   \n",
       "\n",
       "    split 10  \n",
       "0       Test  \n",
       "1      Train  \n",
       "2      Train  \n",
       "3      Train  \n",
       "4      Train  \n",
       "..       ...  \n",
       "437    Train  \n",
       "438    Train  \n",
       "439    Train  \n",
       "440    Train  \n",
       "441    Train  \n",
       "\n",
       "[442 rows x 10 columns]"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "skf = ShuffleSplit(10)\n",
    "N_samples = len(diabetes_y)\n",
    "ss_tt_df = pd.DataFrame(index=list(range(N_samples)))\n",
    "i = 1\n",
    "for train_idx, test_idx in skf.split(diabetes_X, diabetes_y):\n",
    "    ss_tt_df['split ' + str(i)] = ['unused']*N_samples\n",
    "    ss_tt_df['split ' + str(i)][train_idx] = 'Train'\n",
    "    ss_tt_df['split ' + str(i)][test_idx] = 'Test'\n",
    "    i +=1\n",
    "\n",
    "ss_tt_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'sns' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-39-384193e0e11c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mcmap\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolor_palette\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"tab10\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m g = sns.heatmap(ss_tt_df.replace({'Test':1,'Train':0}),cmap=cmap[7:9],cbar_kws={'ticks':[.25,.75]},linewidths=0,\n\u001b[1;32m      3\u001b[0m     linecolor='gray')\n\u001b[1;32m      4\u001b[0m \u001b[0mcolorbar\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcollections\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolorbar\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mcolorbar\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_ticklabels\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Train'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'Test'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'sns' is not defined"
     ]
    }
   ],
   "source": [
    "cmap = sns.color_palette(\"tab10\",10)\n",
    "g = sns.heatmap(ss_tt_df.replace({'Test':1,'Train':0}),cmap=cmap[7:9],cbar_kws={'ticks':[.25,.75]},linewidths=0,\n",
    "    linecolor='gray')\n",
    "colorbar = g.collections[0].colorbar\n",
    "colorbar.set_ticklabels(['Train','Test'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we see the samples in each training set (gray along the columns) are a random subset of all of all of the samples.\n",
    "\n",
    "And check the usage of each sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "172"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(ss_tt_df.apply(count_test,axis = 1) ==1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "and exactly 9 training sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(ss_tt_df.apply(count_test,axis = 1) ==9)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And the size of the splits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "split 1     45\n",
       "split 2     45\n",
       "split 3     45\n",
       "split 4     45\n",
       "split 5     45\n",
       "split 6     45\n",
       "split 7     45\n",
       "split 8     45\n",
       "split 9     45\n",
       "split 10    45\n",
       "dtype: int64"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ss_tt_df.apply(count_test,axis = 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "and training set:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "split 1     397\n",
       "split 2     397\n",
       "split 3     397\n",
       "split 4     397\n",
       "split 5     397\n",
       "split 6     397\n",
       "split 7     397\n",
       "split 8     397\n",
       "split 9     397\n",
       "split 10    397\n",
       "dtype: int64"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ss_tt_df.apply(count_train,axis = 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Again the same sizes"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "text_representation": {
    "extension": ".md",
    "format_name": "myst",
    "format_version": 0.12,
    "jupytext_version": "1.6.0"
   }
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  },
  "source_map": [
   12,
   20,
   31,
   40,
   43,
   48,
   53,
   57,
   62,
   64,
   69,
   71,
   73,
   75,
   84,
   86,
   89,
   91,
   94,
   96,
   104,
   107,
   110,
   112,
   125,
   129,
   132,
   134,
   138,
   142,
   145,
   149,
   153,
   157,
   162,
   167,
   171,
   173,
   185,
   190,
   195,
   198,
   205,
   207,
   220,
   224,
   226,
   231,
   233,
   237,
   246,
   253,
   256,
   259,
   261,
   265,
   267,
   278,
   284,
   289,
   291,
   294,
   296,
   310,
   322,
   327,
   333,
   338,
   340,
   344,
   346,
   351,
   353,
   356,
   358
  ]
 },
 "nbformat": 4,
 "nbformat_minor": 4
}